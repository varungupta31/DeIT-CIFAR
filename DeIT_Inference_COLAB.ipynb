{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwe1NA_1KxJF"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/varungupta31/DeIT-CIFAR.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRPygyq2RRai",
        "outputId": "2aac64a1-979b-4c3c-9531-d80543501139"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imported Important Libraries"
      ],
      "metadata": {
        "id": "SglGFoJvLRKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import torchvision.models as models\n",
        "from sklearn.metrics import *\n",
        "from sklearn.metrics import top_k_accuracy_score\n",
        "import numpy as np\n",
        "from vit import VisionTransformer\n",
        "from deit import DataEfficientImageTransformer as DEIT\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "import yaml\n",
        "# import argparse\n",
        "# from imagenet32_dataloader import ImageNet32\n",
        "torch.manual_seed(123)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVZzu3QhLQOw",
        "outputId": "bbddb8f0-2083-462a-e107-92f9538b34f3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f5bac1633d0>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function For Get Inference From Token"
      ],
      "metadata": {
        "id": "PaZ0jLR4QXMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getInferenceHardToken(model, loader,  device):\n",
        "\n",
        "    model.eval()\n",
        "    cls_token_acc1_log = 0\n",
        "    distill_token_acc1_log = 0\n",
        "    cls_distill_token_acc1_log = 0\n",
        "\n",
        "    cls_token_prec = 0\n",
        "    cls_token_rec = 0\n",
        "    cls_token_fscore = 0\n",
        "    \n",
        "    distill_token_prec = 0\n",
        "    distill_token_rec = 0\n",
        "    distill_token_fscore = 0\n",
        "    \n",
        "    cls_distill_token_prec = 0\n",
        "    cls_distill_token_rec = 0\n",
        "    cls_distill_token_fscore = 0\n",
        "\n",
        "    cls_token_precision = []\n",
        "    cls_token_recall = []\n",
        "    cls_token_f1Score = []\n",
        "    \n",
        "    distill_token_precision = []\n",
        "    distill_token_recall = []\n",
        "    distill_token_f1Score = []\n",
        "    \n",
        "    cls_distill_token_precision = []\n",
        "    cls_distill_token_recall = []\n",
        "    cls_distill_token_f1Score = []\n",
        "    \n",
        "    cls_token_acc3_log = 0\n",
        "    distill_token_acc3_log = 0\n",
        "    cls_distill_token_acc3_log = 0\n",
        "\n",
        "    cls_token_acc5_log = 0\n",
        "    distill_token_acc5_log = 0\n",
        "    cls_distill_token_acc5_log = 0\n",
        "\n",
        "    all_gt = []\n",
        "    all_ground = [] \n",
        "    with torch.no_grad():\n",
        "        for batch_index , (data, gt) in enumerate(loader):\n",
        "            data = data.to(device)\n",
        "            gt = gt.to(device)\n",
        "            scores_cls_token, scores_distill_token = model(data)\n",
        "            scores_cls_distill_token = scores_cls_token + scores_distill_token\n",
        "\n",
        "            scores_cls_token =F.softmax(scores_cls_token, dim = 1)\n",
        "            scores_distill_token = F.softmax(scores_distill_token, dim = 1)\n",
        "            scores_cls_distill_token = F.softmax(scores_cls_distill_token, dim = 1)\n",
        "\n",
        "            scores_cls_token = scores_cls_token.cpu().detach().numpy()\n",
        "            scores_distill_token = scores_distill_token.cpu().detach().numpy()\n",
        "            scores_cls_distill_token = scores_cls_distill_token.cpu().detach().numpy()\n",
        "\n",
        "            gt = gt.cpu().detach().numpy()\n",
        "            \n",
        "            labels = np.arange(0,100)\n",
        "\n",
        "\n",
        "            # if acc_mode == \"top1\":\n",
        "            cls_token_acc1 = top_k_accuracy_score(gt,scores_cls_token, k=1, labels = labels)*100\n",
        "            distill_token_acc1 = top_k_accuracy_score(gt, scores_distill_token, k = 1, labels = labels)*100\n",
        "            cls_distill_token_acc1 = top_k_accuracy_score(gt, scores_cls_distill_token,k = 1, labels = labels)*100\n",
        "\n",
        "            cls_token_prec += precision_score(gt, np.argmax(scores_cls_token, axis=-1), average= \"macro\", zero_division=0)*100\n",
        "            cls_token_rec += recall_score(gt, np.argmax(scores_cls_token, axis=-1), average= \"macro\",zero_division = 0)*100\n",
        "            cls_token_fscore += f1_score(gt, np.argmax(scores_cls_token, axis=-1), average= \"macro\",zero_division = 0)*100\n",
        "\n",
        "            distill_token_prec += precision_score(gt, np.argmax(scores_distill_token, axis=-1), average= \"macro\", zero_division=0)*100\n",
        "            distill_token_rec += recall_score(gt, np.argmax(scores_distill_token, axis=-1), average= \"macro\",zero_division = 0)*100\n",
        "            distill_token_fscore += f1_score(gt, np.argmax(scores_distill_token, axis=-1), average= \"macro\",zero_division = 0)*100\n",
        "\n",
        "            cls_distill_token_prec += precision_score(gt, np.argmax(scores_cls_distill_token, axis=-1), average= \"macro\", zero_division=0)*100\n",
        "            cls_distill_token_rec += recall_score(gt, np.argmax(scores_cls_distill_token, axis=-1), average= \"macro\",zero_division = 0)*100\n",
        "            cls_distill_token_fscore += f1_score(gt, np.argmax(scores_cls_distill_token, axis=-1), average= \"macro\",zero_division = 0)*100\n",
        "\n",
        "\n",
        "            cls_token_acc3 = top_k_accuracy_score(gt,scores_cls_token, k=3, labels = labels)*100\n",
        "            distill_token_acc3 = top_k_accuracy_score(gt, scores_distill_token, k = 3, labels = labels)*100\n",
        "            cls_distill_token_acc3 = top_k_accuracy_score(gt, scores_cls_distill_token,k = 3, labels = labels)*100\n",
        "\n",
        "\n",
        "            cls_token_acc5 = top_k_accuracy_score(gt,scores_cls_token, k=5, labels = labels)*100\n",
        "            distill_token_acc5 = top_k_accuracy_score(gt, scores_distill_token, k = 5, labels = labels)*100\n",
        "            cls_distill_token_acc5 = top_k_accuracy_score(gt, scores_cls_distill_token,k = 5, labels = labels)*100\n",
        "\n",
        "           \n",
        "            \n",
        "            batch_cls_token_precision= cls_token_prec/(batch_index+1)\n",
        "            batch_cls_token_recall= cls_token_rec/(batch_index+1)\n",
        "            batch_cls_token_fscore= cls_token_fscore/(batch_index+1)\n",
        "\n",
        "            batch_distill_token_precision= distill_token_prec/(batch_index+1)\n",
        "            batch_distill_token_recall= distill_token_rec/(batch_index+1)\n",
        "            batch_distill_token_fscore= distill_token_fscore/(batch_index+1)\n",
        "\n",
        "            batch_cls_distill_token_precision= cls_distill_token_prec/(batch_index+1)\n",
        "            batch_cls_distill_token_recall= cls_distill_token_rec/(batch_index+1)\n",
        "            batch_cls_distill_token_fscore= cls_distill_token_fscore/(batch_index+1)\n",
        "\n",
        "\n",
        "            cls_token_precision.append(batch_cls_token_precision)\n",
        "            cls_token_recall.append(batch_cls_token_recall)\n",
        "            cls_token_f1Score.append(batch_cls_token_fscore)\n",
        "            \n",
        "            distill_token_precision.append(batch_distill_token_precision)\n",
        "            distill_token_recall.append(batch_distill_token_recall)\n",
        "            distill_token_f1Score.append(batch_distill_token_fscore)\n",
        "            \n",
        "            cls_distill_token_precision.append(batch_cls_distill_token_precision)\n",
        "            cls_distill_token_recall.append(batch_cls_distill_token_recall)\n",
        "            cls_distill_token_f1Score.append(batch_cls_distill_token_fscore)\n",
        "\n",
        "\n",
        "            cls_token_acc1_log += cls_token_acc1\n",
        "            distill_token_acc1_log += distill_token_acc1\n",
        "            cls_distill_token_acc1_log += cls_distill_token_acc1 \n",
        "\n",
        "            cls_token_acc3_log += cls_token_acc3\n",
        "            distill_token_acc3_log += distill_token_acc3\n",
        "            cls_distill_token_acc3_log += cls_distill_token_acc3\n",
        "\n",
        "            cls_token_acc5_log += cls_token_acc5\n",
        "            distill_token_acc5_log += distill_token_acc5\n",
        "            cls_distill_token_acc5_log += cls_distill_token_acc5\n",
        "\n",
        "        cls_token_precision = np.mean(cls_token_precision)\n",
        "        cls_token_recall = np.mean(cls_token_recall)\n",
        "        cls_token_f1Score = np.mean(cls_token_f1Score)\n",
        "        \n",
        "        distill_token_precision = np.mean(distill_token_precision)\n",
        "        distill_token_recall = np.mean(distill_token_recall)\n",
        "        distill_token_f1Score = np.mean(distill_token_f1Score)\n",
        "        \n",
        "        cls_distill_token_precision = np.mean(cls_distill_token_precision)\n",
        "        cls_distill_token_recall = np.mean(cls_distill_token_recall)\n",
        "        cls_distill_token_f1Score = np.mean(cls_distill_token_f1Score)\n",
        "\n",
        "        return (cls_token_acc1_log/(batch_index+1),\n",
        "                    distill_token_acc1_log/(batch_index+1),\n",
        "                    cls_distill_token_acc1_log/(batch_index+1),\n",
        "                    cls_token_precision, cls_token_recall, \n",
        "                    distill_token_precision, distill_token_recall,\n",
        "                    cls_distill_token_precision, cls_distill_token_recall,\n",
        "                    cls_token_f1Score, distill_token_f1Score, cls_distill_token_f1Score,\n",
        "                    cls_token_acc3_log/(batch_index+1),\n",
        "                    distill_token_acc3_log/(batch_index+1),\n",
        "                    cls_distill_token_acc3_log/(batch_index+1),\n",
        "                    cls_token_acc5_log/(batch_index+1),\n",
        "                    distill_token_acc5_log/(batch_index+1),\n",
        "                    cls_distill_token_acc5_log/(batch_index+1)\n",
        "                    )"
      ],
      "metadata": {
        "id": "X3IWl6tcLiNF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function For Get Inference From Without Token"
      ],
      "metadata": {
        "id": "IqogtfmmQhbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getInference(model, loader,  device):\n",
        "    model.eval()\n",
        "    out_acc1 = 0\n",
        "    out_acc3 = 0\n",
        "    out_acc5 = 0\n",
        "    out_precision = []\n",
        "    out_recall = []\n",
        "    out_f1Score = []\n",
        "    f1Score = 0\n",
        "    prec = 0\n",
        "    rec = 0\n",
        "    for batch_index ,(data, gt) in enumerate(loader):\n",
        "        data = data.to(device)\n",
        "        gt = gt.to(device)\n",
        "        scores = model(data)\n",
        "        scores = F.softmax(scores, dim = 1)\n",
        "        scores = scores.cpu().detach().numpy()\n",
        "        gt = gt.cpu().detach().numpy()\n",
        " \n",
        "        labels = np.arange(0,100)\n",
        "\n",
        "\n",
        "        acc1 = top_k_accuracy_score(gt,scores, k=1, labels = labels)*100\n",
        "        acc3 = top_k_accuracy_score(gt,scores, k=3, labels = labels)*100\n",
        "        acc5 = top_k_accuracy_score(gt,scores, k=5, labels = labels)*100\n",
        "\n",
        "        out_acc1 += acc1\n",
        "        out_acc3 += acc3\n",
        "        out_acc5 += acc5\n",
        "        \n",
        "\n",
        "        prec += precision_score(gt, np.argmax(scores, axis=-1), average = \"macro\", zero_division = 0)*100\n",
        "        rec += recall_score(gt, np.argmax(scores, axis=-1),average  = \"macro\",zero_division = 0)*100\n",
        "        f1Score += f1_score(gt, np.argmax(scores, axis=-1), average = \"macro\",zero_division = 0)*100\n",
        "        \n",
        "        batch_prec = prec/(batch_index+1)\n",
        "        batch_rec = rec/(batch_index+1)\n",
        "        batch_f1Score = f1Score/(batch_index+1)\n",
        "      \n",
        "        out_precision.append(batch_prec)\n",
        "        out_recall.append(batch_rec)\n",
        "        out_f1Score.append(batch_f1Score)\n",
        "    \n",
        "    out_precision = np.mean(out_precision)\n",
        "    out_recall = np.mean(out_recall)\n",
        "    out_f1Score = np.mean(out_f1Score)\n",
        "    return (out_acc1/(batch_index+1),\n",
        "                out_acc3/(batch_index+1),\n",
        "                out_acc5/(batch_index+1),\n",
        "                out_precision,out_recall,\n",
        "                out_f1Score)"
      ],
      "metadata": {
        "id": "WCywoB6XL3JQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def doInference(loader, mode = \"distilled_token\", model= None,  device=\"cuda\"):\n",
        "    if mode == \"distilled_token\":\n",
        "\n",
        "        final_model = model\n",
        "        \n",
        "        loader = loader\n",
        "        device = device\n",
        "        \n",
        "\n",
        "        \n",
        "        if final_model == None:\n",
        "            print(\"No model is provided!!\")\n",
        "        else:\n",
        "            clsTokenAcc1, distillTokenAcc1, clsDistillTokenAcc1, cls_token_precision, cls_token_recall,distill_token_precision, distill_token_recall,cls_distill_token_precision, cls_distill_token_recall, cls_token_f1Score, distill_token_f1Score, cls_distill_token_f1Score,clsTokenAcc3, distillTokenAcc3, clsDistillTokenAcc3,clsTokenAcc5, distillTokenAcc5, clsDistillTokenAcc5= getInferenceHardToken(final_model,loader, device)\n",
        "            print(\"Final Top-1 Accuracy\")\n",
        "     \n",
        "            print(f\"cls_token_acc:{clsTokenAcc1}\\n distill_token_acc:{distillTokenAcc1}\\n cls_distill_token_acc:{clsDistillTokenAcc1}\\n\"\n",
        "      f\"prec_cls_token: {cls_token_precision}\\n recall_cls_token: {cls_token_recall}\\n cls_token_f1Score: {cls_token_f1Score}\"\n",
        "      f\"prec_distill_token:{distill_token_precision}\\n recall_distill_token: {distill_token_recall}\\n distill_token_f1Score : {distill_token_f1Score} \"\n",
        "             f\"prec_class_dist_token:{cls_distill_token_precision}\\n recall_class_distill_token:{cls_distill_token_recall}\\n cls_distill_token_f1Score : {cls_distill_token_f1Score}\")\n",
        "     \n",
        "\n",
        "            print(\"************************************\")\n",
        "\n",
        "            print(\"Final Top-3 Accuracy\")\n",
        "            print(f\"cls_token_acc:{clsTokenAcc3}\\n distill_token_acc:{distillTokenAcc3}\\n cls_distill_token_acc:{clsDistillTokenAcc3}\\n\")\n",
        "            print(\"************************************\")\n",
        "\n",
        "            print(\"Final Top-5 Accuracy\")\n",
        "            print(f\"cls_token_acc:{clsTokenAcc5}\\n distill_token_acc:{distillTokenAcc5}\\n cls_distill_token_acc:{clsDistillTokenAcc5}\\n\")\n",
        "     \n",
        "\n",
        "        \n",
        "\n",
        "    else:\n",
        "        final_model = model\n",
        "        # print(\"entering.....\")\n",
        "        loader = loader\n",
        "        device = device\n",
        "        \n",
        "        if final_model == None:\n",
        "            print(\"No model is provided!!\")\n",
        "        else:\n",
        "            \n",
        "            acc_1,acc_3,acc_5,out_precision,out_recall,out_f1Score = getInference(final_model,loader,  device)\n",
        "            print(\"Final Accuracy.....\")\n",
        "            print(f\"acc@1:{acc_1}\\t acc@3 :{acc_3}\\t acc@5 :{acc_5} precision:{out_precision}\\t recall:{out_recall}\\t f1_score:{out_f1Score}\")"
      ],
      "metadata": {
        "id": "pveCqL5BL9gv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "transforms = transforms.Compose([transforms.ToTensor(), \n",
        "                            transforms.Normalize((0.2675, 0.2565, 0.2761),(0.5071, 0.4867, 0.4408))])\n",
        "#load the test set\n",
        "testset = datasets.CIFAR100(root = '/', train = False, transform = transforms, download = True)\n",
        "batch_size = 1024\n",
        "test_dataloaders = DataLoader(testset, batch_size = batch_size, shuffle = \"False\", num_workers = 4)"
      ],
      "metadata": {
        "id": "dANn5jCiMIDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "mIRkBoEXMPDM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_config = {\n",
        "    \"img_size\": 32,\n",
        "    \"in_chans\": 3,\n",
        "    \"patch_size\": 16,\n",
        "    \"embed_dim\": 768,\n",
        "    \"depth\": 12,\n",
        "    \"n_heads\": 12,\n",
        "    \"qkv_bias\": True,\n",
        "    \"mlp_ratio\": 4,\n",
        "}"
      ],
      "metadata": {
        "id": "2zGvuPboMRqR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Initializing the Model"
      ],
      "metadata": {
        "id": "Q1kDf70cP8DS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = DEIT(**custom_config)"
      ],
      "metadata": {
        "id": "CSlNGhw5MZVV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading The Model "
      ],
      "metadata": {
        "id": "pC_4BAJQQCNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the  model\n",
        "saved_model_path = \"/content/drive/MyDrive/smai_project_trained_files/vit_b_reg16gf_hard_dist_token_24\"\n",
        "model.load_state_dict(torch.load(saved_model_path))\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlZ0KdGlMfjr",
        "outputId": "e0ab51bb-f37a-4c2c-9120-180cf88ba2f9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataEfficientImageTransformer(\n",
              "  (patch_embed): PatchEmbed(\n",
              "    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
              "  )\n",
              "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "  (blocks): ModuleList(\n",
              "    (0-11): 12 x Block(\n",
              "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): MLP(\n",
              "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "  (cls_head): Linear(in_features=768, out_features=100, bias=True)\n",
              "  (dist_head): Linear(in_features=768, out_features=100, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_num_param = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total number of parameters for:{total_num_param}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hazxglQVMprP",
        "outputId": "79addfd4-557c-4d60-b625-96f6c25978a9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters for:85806536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doInference(mode = \"distilled_token\" , model= model, loader= test_dataloaders)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cafrBqqENEnJ",
        "outputId": "74aa8c6b-bf7c-476c-f6ef-b73995dc449a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Top-1 Accuracy\n",
            "cls_token_acc:33.63958864795918\n",
            " distill_token_acc:33.09809470663265\n",
            " cls_distill_token_acc:33.929567920918366\n",
            "prec_cls_token: 34.68550067225836\n",
            " recall_cls_token: 34.027773573834544\n",
            " cls_token_f1Score: 33.04515976814497prec_distill_token:33.92327389693391\n",
            " recall_distill_token: 33.15488635350676\n",
            " distill_token_f1Score : 32.10729739230323 prec_class_dist_token:34.69782749425314\n",
            " recall_class_distill_token:33.86154537588611\n",
            " cls_distill_token_f1Score : 32.950956906753014\n",
            "************************************\n",
            "Final Top-3 Accuracy\n",
            "cls_token_acc:52.00972576530612\n",
            " distill_token_acc:52.14704241071429\n",
            " cls_distill_token_acc:52.95459980867347\n",
            "\n",
            "************************************\n",
            "Final Top-5 Accuracy\n",
            "cls_token_acc:60.48290019132653\n",
            " distill_token_acc:60.92534279336735\n",
            " cls_distill_token_acc:61.15672831632653\n",
            "\n"
          ]
        }
      ]
    }
  ]
}