# -*- coding: utf-8 -*-
"""Disagreement.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18lqzeFToUJGu35_QLiXeUFFLGP2ZCBba
"""

import torch
import torchvision
import torchvision.datasets as datasets
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import torchvision.models as models
import torch.nn as nn
# import timm
import torch.nn.functional as F
import os
import torchvision.models as models
# from teacher_model_18 import teacher_model
from sklearn.metrics import *
from sklearn.metrics import top_k_accuracy_score
import numpy as np
from vit import VisionTransformer
from deit import DataEfficientImageTransformer as DEIT
torch.manual_seed(123)
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score

#apply transformation
transforms = transforms.Compose([transforms.ToTensor(), 
							transforms.Normalize((0.2675, 0.2565, 0.2761),(0.5071, 0.4867, 0.4408))])
#load the test set
testset = datasets.CIFAR100(root = "./", train = False, transform = transforms, download = True)
batch_size = 1024
test_dataloaders = DataLoader(testset, batch_size = batch_size, shuffle = "False", num_workers = 4)

#check the device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#Initializing the model
# model = models.regnet_y_16gf()
# num_ftrs = model.fc.in_features
# model.fc = nn.Linear(num_ftrs, 100)

custom_config = {
        "img_size": 32,
        "in_chans": 3,
        "patch_size": 16,
        "embed_dim": 768,
        "depth": 12,
        "n_heads": 12,
        "qkv_bias": True,
        "mlp_ratio": 4,
}

model1 = VisionTransformer(**custom_config)
model1 = nn.Sequential(model1, nn.Linear(1000,100, bias=True))

model2 = DEIT(**custom_config)
#model1 = VisionTransformer(**custom_config)
#model1 = nn.Sequential(model1, nn.Linear(1000,100, bias=True))
#model2 = models.regnet_y_16gf()
#num_ftrs = model2.fc.in_features
#model2.fc = nn.Linear(num_ftrs,100)



#calculating the total number of parameters
#total_num_param = sum(p.numel() for p in model1.parameters())
#print(f"Total number of parameters for:{total_num_param}")

#loading the  model
saved_model2_path = "/ssd_scratch/cvit/varun/trained_files/vit_b_regnet16gf_imgnetFT_hardDist_token/vit_b_reg16gf_hard_dist_token_28"
saved_model1_path = "/ssd_scratch/cvit/varun/trained_files/vit_b_regnet16gf_imgnetFT_softDift/vit_small_regnet16gf_distill_43"


model1.load_state_dict(torch.load(saved_model1_path))
model2.load_state_dict(torch.load(saved_model2_path))
#model1_load= torch.load(saved_model1_path).to(device)

model1.to(device)
model2.to(device)

total_num_param = sum(p.numel() for p in model1.parameters())
print(f"Total number of parameters for model1:{total_num_param}")

total_num_param = sum(p.numel() for p in model2.parameters())
print(f"Total number of parameters for model2:{total_num_param}")
#model2.load_state_dict(torch.load(saved_model_path))
#model2.to(device)
# doInference(mode = "distilled_token",model= model,loader= test_dataloaders)

disagree_count = 0
total_samples = 0

model1.eval()

with torch.no_grad():
  for batch_index, (data, gt) in enumerate(test_dataloaders):
    data = data.to(device)
    gt = gt.to(device)
    
    scores_cls_token, scores_distill_token = model2(data)
    scores_cls_distill_token = scores_cls_token + scores_distill_token
    #scores_cls_token =F.softmax(scores_cls_token, dim = 1)
    #scores_distill_token = F.softmax(scores_distill_token, dim = 1)
    #scores_cls_distill_token = F.softmax(scores_cls_distill_token, dim=1)


    scores1 = model1(data)
    #scores2 = model2(data)

    #scores = F.softmax(scores, dim =1)

    #preds1 = torch.argmax(scores_cls_distill_token, dim=1)
    preds1 = torch.argmax(scores1, dim=1)
    preds2 = torch.argmax(scores_cls_token, dim=1)

    
    preds1_np = preds1.cpu().detach().numpy()
    preds2_np = preds2.cpu().detach().numpy()
    #gt_np = gt.cpu().detach().numpy()
    
    disagree_count += np.sum(preds1_np != preds2_np)
    total_samples += len(preds1_np)
    
disagree_rate = disagree_count / total_samples

print(disagree_rate)

