
























Adjusting learning rate of group 0 to 1.8000e-03.
Before LR Scheduler --> 0.002 || After LR Scheduler --> 0.0018000000000000002
--------- After Epoch 0 : Train Loss 1267.8020417586617 ||  Validation Loss 877.3712158203125 || Validation Accuracy 0.011 || Train Accuracy 0.0108125---------
























Adjusting learning rate of group 0 to 1.6200e-03.
Before LR Scheduler --> 0.0018000000000000002 || After LR Scheduler --> 0.0016200000000000001
--------- After Epoch 1 : Train Loss 792.6663951044497 ||  Validation Loss 680.595703125 || Validation Accuracy 0.008 || Train Accuracy 0.011416666666666667---------























Adjusting learning rate of group 0 to 1.4580e-03.
Before LR Scheduler --> 0.0016200000000000001 || After LR Scheduler --> 0.001458
--------- After Epoch 2 : Train Loss 571.2088171917459 ||  Validation Loss 466.7205810546875 || Validation Accuracy 0.008 || Train Accuracy 0.01175---------
























Adjusting learning rate of group 0 to 1.3122e-03.
Before LR Scheduler --> 0.001458 || After LR Scheduler --> 0.0013122000000000001
--------- After Epoch 3 : Train Loss 376.9901978865914 ||  Validation Loss 284.76171875 || Validation Accuracy 0.01 || Train Accuracy 0.013395833333333333---------
























Adjusting learning rate of group 0 to 1.1810e-03.
Before LR Scheduler --> 0.0013122000000000001 || After LR Scheduler --> 0.00118098
--------- After Epoch 4 : Train Loss 234.57689633576766 ||  Validation Loss 177.9132080078125 || Validation Accuracy 0.0135 || Train Accuracy 0.0144375---------























Adjusting learning rate of group 0 to 1.0629e-03.
Before LR Scheduler --> 0.00118098 || After LR Scheduler --> 0.001062882
--------- After Epoch 5 : Train Loss 147.50259100872537 ||  Validation Loss 121.53711700439453 || Validation Accuracy 0.0125 || Train Accuracy 0.014166666666666666---------
























Adjusting learning rate of group 0 to 9.5659e-04.
Before LR Scheduler --> 0.001062882 || After LR Scheduler --> 0.0009565938
--------- After Epoch 6 : Train Loss 101.90655650263247 ||  Validation Loss 85.68741607666016 || Validation Accuracy 0.013 || Train Accuracy 0.015270833333333334---------
























Adjusting learning rate of group 0 to 8.6093e-04.
Before LR Scheduler --> 0.0009565938 || After LR Scheduler --> 0.00086093442
--------- After Epoch 7 : Train Loss 75.470505092455 ||  Validation Loss 65.3890151977539 || Validation Accuracy 0.017 || Train Accuracy 0.016895833333333332---------
























Adjusting learning rate of group 0 to 7.7484e-04.
Before LR Scheduler --> 0.00086093442 || After LR Scheduler --> 0.000774840978
--------- After Epoch 8 : Train Loss 57.861321324887484 ||  Validation Loss 47.733360290527344 || Validation Accuracy 0.0195 || Train Accuracy 0.016854166666666667---------























Adjusting learning rate of group 0 to 6.9736e-04.
Before LR Scheduler --> 0.000774840978 || After LR Scheduler --> 0.0006973568802
--------- After Epoch 9 : Train Loss 42.85989529153575 ||  Validation Loss 34.22603988647461 || Validation Accuracy 0.017 || Train Accuracy 0.016916666666666667---------























Adjusting learning rate of group 0 to 6.2762e-04.
Before LR Scheduler --> 0.0006973568802 || After LR Scheduler --> 0.0006276211921800001
--------- After Epoch 10 : Train Loss 33.05861406740935 ||  Validation Loss 30.151111602783203 || Validation Accuracy 0.0225 || Train Accuracy 0.017541666666666667---------
























Adjusting learning rate of group 0 to 5.6486e-04.
Before LR Scheduler --> 0.0006276211921800001 || After LR Scheduler --> 0.0005648590729620001
--------- After Epoch 11 : Train Loss 30.655289940212082 ||  Validation Loss 28.36285972595215 || Validation Accuracy 0.018 || Train Accuracy 0.018145833333333333---------
























Adjusting learning rate of group 0 to 5.0837e-04.
Before LR Scheduler --> 0.0005648590729620001 || After LR Scheduler --> 0.0005083731656658001
--------- After Epoch 12 : Train Loss 29.57446413454802 ||  Validation Loss 28.040334701538086 || Validation Accuracy 0.022 || Train Accuracy 0.018666666666666668---------























Adjusting learning rate of group 0 to 4.5754e-04.
Before LR Scheduler --> 0.0005083731656658001 || After LR Scheduler --> 0.0004575358490992201
--------- After Epoch 13 : Train Loss 28.863855196082074 ||  Validation Loss 27.596214294433594 || Validation Accuracy 0.0185 || Train Accuracy 0.018916666666666665---------
























Adjusting learning rate of group 0 to 4.1178e-04.
Before LR Scheduler --> 0.0004575358490992201 || After LR Scheduler --> 0.0004117822641892981
--------- After Epoch 14 : Train Loss 28.04470385675845 ||  Validation Loss 26.41168975830078 || Validation Accuracy 0.017 || Train Accuracy 0.0198125---------
























Adjusting learning rate of group 0 to 3.7060e-04.
Before LR Scheduler --> 0.0004117822641892981 || After LR Scheduler --> 0.00037060403777036834
--------- After Epoch 15 : Train Loss 27.396972573321797 ||  Validation Loss 25.969417572021484 || Validation Accuracy 0.0235 || Train Accuracy 0.021520833333333333---------























Adjusting learning rate of group 0 to 3.3354e-04.
Before LR Scheduler --> 0.00037060403777036834 || After LR Scheduler --> 0.0003335436339933315
--------- After Epoch 16 : Train Loss 26.847026824951172 ||  Validation Loss 25.56355857849121 || Validation Accuracy 0.0195 || Train Accuracy 0.0205---------
























Adjusting learning rate of group 0 to 3.0019e-04.
Before LR Scheduler --> 0.0003335436339933315 || After LR Scheduler --> 0.0003001892705939984
--------- After Epoch 17 : Train Loss 26.559907332710598 ||  Validation Loss 24.903413772583008 || Validation Accuracy 0.0175 || Train Accuracy 0.019916666666666666---------






















Adjusting learning rate of group 0 to 2.7017e-04.
Before LR Scheduler --> 0.0003001892705939984 || After LR Scheduler --> 0.0002701703435345986
--------- After Epoch 18 : Train Loss 25.976490020751953 ||  Validation Loss 24.181880950927734 || Validation Accuracy 0.0205 || Train Accuracy 0.019833333333333335---------























Adjusting learning rate of group 0 to 2.4315e-04.
Before LR Scheduler --> 0.0002701703435345986 || After LR Scheduler --> 0.00024315330918113872
--------- After Epoch 19 : Train Loss 25.558018642923106 ||  Validation Loss 24.349456787109375 || Validation Accuracy 0.0175 || Train Accuracy 0.020625---------
























Adjusting learning rate of group 0 to 2.1884e-04.
Before LR Scheduler --> 0.00024315330918113872 || After LR Scheduler --> 0.00021883797826302486
--------- After Epoch 20 : Train Loss 25.197170008783754 ||  Validation Loss 24.179458618164062 || Validation Accuracy 0.021 || Train Accuracy 0.020770833333333332---------
























Adjusting learning rate of group 0 to 1.9695e-04.
Before LR Scheduler --> 0.00021883797826302486 || After LR Scheduler --> 0.00019695418043672237
--------- After Epoch 21 : Train Loss 24.838585563327957 ||  Validation Loss 23.629833221435547 || Validation Accuracy 0.0175 || Train Accuracy 0.021354166666666667---------























Adjusting learning rate of group 0 to 1.7726e-04.
Before LR Scheduler --> 0.00019695418043672237 || After LR Scheduler --> 0.00017725876239305013
--------- After Epoch 22 : Train Loss 24.531653113987137 ||  Validation Loss 23.146406173706055 || Validation Accuracy 0.0205 || Train Accuracy 0.020479166666666666---------
























Adjusting learning rate of group 0 to 1.5953e-04.
Before LR Scheduler --> 0.00017725876239305013 || After LR Scheduler --> 0.00015953288615374513
--------- After Epoch 23 : Train Loss 24.35243382661239 ||  Validation Loss 22.787446975708008 || Validation Accuracy 0.0205 || Train Accuracy 0.020291666666666666---------























Adjusting learning rate of group 0 to 1.4358e-04.
Before LR Scheduler --> 0.00015953288615374513 || After LR Scheduler --> 0.0001435795975383706
--------- After Epoch 24 : Train Loss 24.065640408059824 ||  Validation Loss 22.815996170043945 || Validation Accuracy 0.0185 || Train Accuracy 0.021270833333333333---------





Epoch 26/100 : |███████████████------------------------------------------------------------| 20.83% [5/24 00:15<00:58]
Traceback (most recent call last):
  File "/home2/varungupta/DeIT-CIFAR/train_vit_scratch.py", line 249, in <module>
    vit_train_log, vit_val_log, vit_train_time, vit_min_val_loss, vit_log_best_train_loss, vit_best_epoch, vit_val_acc = train(epochs = config['epochs'],
                                                                                                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home2/varungupta/DeIT-CIFAR/train_vit_scratch.py", line 147, in train
    for train_batch, (data, target) in enumerate(progress_bar(train_data_loader, parent=mb)):
  File "/home2/varungupta/miniconda3/envs/smai/lib/python3.11/site-packages/fastprogress/fastprogress.py", line 41, in __iter__
    for i,o in enumerate(self.gen):
  File "/home2/varungupta/miniconda3/envs/smai/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 634, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/home2/varungupta/miniconda3/envs/smai/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 678, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home2/varungupta/miniconda3/envs/smai/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home2/varungupta/miniconda3/envs/smai/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/home2/varungupta/miniconda3/envs/smai/lib/python3.11/site-packages/torch/utils/data/dataset.py", line 298, in __getitem__
    return self.dataset[self.indices[idx]]
           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
  File "/home2/varungupta/miniconda3/envs/smai/lib/python3.11/site-packages/torchvision/datasets/cifar.py", line 118, in __getitem__
    img = self.transform(img)
          ^^^^^^^^^^^^^^^^^^^
  File "/home2/varungupta/miniconda3/envs/smai/lib/python3.11/site-packages/torchvision/transforms/transforms.py", line 95, in __call__
    img = t(img)
          ^^^^^^
  File "/home2/varungupta/miniconda3/envs/smai/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home2/varungupta/miniconda3/envs/smai/lib/python3.11/site-packages/torchvision/transforms/transforms.py", line 1379, in forward
    return F.rotate(img, angle, self.interpolation, self.expand, self.center, fill)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home2/varungupta/miniconda3/envs/smai/lib/python3.11/site-packages/torchvision/transforms/functional.py", line 1139, in rotate
    matrix = _get_inverse_affine_matrix(center_f, -angle, [0.0, 0.0], 1.0, [0.0, 0.0])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home2/varungupta/miniconda3/envs/smai/lib/python3.11/site-packages/torchvision/transforms/functional.py", line 1046, in _get_inverse_affine_matrix
    b = -math.cos(rot - sy) * math.tan(sx) / math.cos(sy) - math.sin(rot)
                              ^^^^^^^^^^^^
KeyboardInterrupt